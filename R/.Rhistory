#*****************************************************
#Plot population distribution and order stats pdf's
curve(f(x),from=0, to=1,col="black",ylim=c(0,5),lwd=3)
for (k in orderstatsneeded ) {
curve(kthOrderStatpdf(k,x),col=k,add=TRUE)
}
legend("topleft",legend=c(1:n),pch=15,col=c(1:n))
# General R Script to compare two estimators
# Initially set up to reproduce Lecture Module 2 slides 13-18 exponential example
#Define population distribution**********************
#method 1 - use inbuilt R command
popdistn<-function(n){
rexp(n,rate=1/5)
# rpois(n,lambda=5)
}
#method 2
#if an R inbuilt command is not unavailable consider using the inverse transformation method.
#*****************************************************
#define estimators
estimator1 <- function(sample){
mean(sample)
}
estimator2 <- function(sample){
sd(sample)
}
#*****************************************************
#Set number of repetitions and sample size
nreps<-2000
samplesize<-100
#*****************************************************
#create samples
observed_est_1<- replicate(nreps, estimator1(popdistn(samplesize)))
observed_est_2<- replicate(nreps, estimator2(popdistn(samplesize)))
#*****************************************************
# Display data
#set plot range
lower=min(c(observed_est_1,observed_est_2))
upper=max(c(observed_est_1,observed_est_2))
#plot histograms
par(mfrow = c(2,1))
hist(observed_est_1,xlim=c(lower,upper),main="Estimator 1 Histogram",nclass=20)
hist(observed_est_2,xlim=c(lower,upper),main="Estimator 2 Histogram",nclass=20)
#boxplots
boxplot(observed_est_1, observed_est_2, horizontal = TRUE, names = c("Estimator1", "Estimator2"),
col = c("yellow", "orange"))
#summaries
print(summary(observed_est_1))
print(summary(observed_est_2))
print(c("Estimator 1 se: ",round(sd(observed_est_1),4)))
print(c("Estimator 2 se: ",round(sd(observed_est_2),4)))
print(c("Ratio of sd(Est2)/sd(Est1 :",round(sd(observed_est_2)/sd(observed_est_1),4)))
tasmania <- read.csv("tasmania.csv") # load data
normal.fit <- fitdistr(x = s1, densfun = "normal")
library(MASS)
# Prepares the Gumbel pdf:
dgumbel <- function(x, mu, sigma)
exp((mu - x) / sigma - exp((mu - x) / sigma)) / sigma
# Fits the Gumbel distribution
gumbel.fit <- fitdistr(x = s1, densfun = dgumbel,
start = list(mu = 50, sigma = 10))
library(MASS)
# Prepares the Gumbel pdf:
dgumbel <- function(x, mu, sigma)
exp((mu - x) / sigma - exp((mu - x) / sigma)) / sigma
# Fits the Gumbel distribution
gumbel.fit <- fitdistr(x = ProdAB%ProdA, densfun = dgumbel,
neg.llk <- function(theta) { # negative log-likelihood
mu    <- theta[1]
sigma <- theta[2]
out   <- -sum(log(dgumbel(s1, mu, sigma)))
return(out)
}
fit <- optim(c(50, 10), neg.llk) # fits MLEs
neg.llk <- function(theta) { # negative log-likelihood
mu    <- theta[1]
sigma <- theta[2]
out   <- -sum(log(dgumbel(x, mu, sigma)))
return(out)
}
fit <- optim(c(50, 10), neg.llk) # fits MLEs
theta.hat <- fit$par # returns estimates
theta.hat
data <- read.table("candies.txt", header = TRUE)  # load the data
knitr::opts_chunk$set(echo = TRUE)
install.packages("binom")
install.packages("BSDA")
install.packages(DescTools)
install.packages("foreign")
#install.packages("binom")
#install.packages("BSDA")
install.packages("DescTools")
#install.packages("foreign")
#install.packages("binom")
#install.packages("BSDA")
install.packages("DescTools")
#install.packages("foreign")
install.packages("DescTools")
knitr::opts_chunk$set(echo = TRUE)
data1 <- read.csv("Apartment.csv", header = TRUE)
data2 <- read.table("ProdAB.txt", header = TRUE)
data1 <- read.table("ProdAB.txt", header = TRUE)
data2 <- read.csv("Apartment.csv", header = TRUE)
quantile(data1, type = "type 7")
quantile(data1, type = 7)
data1 <- read.table("ProdAB.txt", header = TRUE)
data2 <- read.csv("Apartment.csv", header = TRUE)
proda <- data1$ProdA
prodb <- data1$ProdB
quantile(proda, type = 7)
var.test(proda,prodb, conf.level=0.90)
diff<-proda-prodb
t.test(diff, alternative = "less")
qt(0.975, 10 + 10 -2)
t.test(prodb, con.level = 0.90)
t.test(prodb, conf.level = 0.90)
?t.test
t.test(prodb, conf.level = 0.90)
qt(0.05, 10 + 10 -2)
t.test(proda, mu = 10)
tsum.test(proda, mu = 10)
library(BSDA)
tsum.test(proda, mu = 10)
library(BSDA)
tsum.test(proda, mu = 10,s.x=var(proda), n.x=10)
library(BSDA)
tsum.test( mu = 10,s.x=var(proda), n.x=10)
library(BSDA)
tsum.test( mu = 10,mean.x = mean(proda), s.x=var(proda), n.x=10)
?pt
pt(-2,9)
?pt
pt(-2,9) + (1-pt(2), 9)
?pt
pt(-2,9) + (1-pt(2, 9)
?pt
pt(-2,9) + (1-pt(2, 9))
size <- data2$size
price <- data2$price
cor(size, price)
m1 <- lm(price ~ size)
m1 <- lm(price ~ size)
summary(m1)
m1 <- lm(price ~ size)
summary(m1)
mean(size)
confint(m1)
confint(m1, level=0.90)
newdata <- data.frame(size = 80)
predict(m1, newdata, interval = "prediction", level = 0.90)
newdata <- data.frame(size = 80)
predict(m1, newdata, interval = "prediction", level = 0.95)
diff<-proda-prodb
t.test(diff, alternative = "less", var.equal = TRUE)
qt(0.05, 10 - 1)
# not qt(0.05, 10 - 1)
qt(0.95, 10 - 1)
diff<-proda-prodb
t.test(diff, alternative = "less", var.equal = TRUE)
diff<-proda-prodb
t.test(proa, prodb, alternative = "less", var.equal = TRUE)
diff<-proda-prodb
t.test(proda, prodb, alternative = "less", var.equal = TRUE)
knitr::opts_chunk$set(echo = TRUE)
data1 <- read.table("HExer.txt", header = TRUE)
data2 <- read.csv("sales.csv", header = TRUE)
data1 <- read.table("HExer.txt", header = TRUE)
day  <- factor(data1$days)
data2 <- read.csv("sales.csv", header = TRUE)
rm(list=ls())
#install.packages("binom")
#install.packages("BSDA")
#install.packages("DescTools")
#install.packages("foreign")
library(binom)
library(BSDA)
library(DescTools)
library(foreign)
data1 <- read.table("HExer.txt", header = TRUE)
day  <- factor(data1$days)
data2 <- read.csv("sales.csv", header = TRUE)
data1 <- read.table("HExer.txt", header = TRUE)
day  <- factor(data1$days)
table(day)
data2 <- read.csv("sales.csv", header = TRUE)
data1 <- read.table("HExer.txt", header = TRUE)
data2 <- read.csv("sales.csv", header = TRUE)
day  <- factor(data2$days)
table(day)
data1 <- read.table("HExer.txt", header = TRUE)
data2 <- read.csv("sales.csv", header = TRUE)
day  <- factor(data2$days)
table(day)
sale <- data2$sales
data1 <- read.table("HExer.txt", header = TRUE)
data2 <- read.csv("sales.csv", header = TRUE)
day  <- factor(data2$days)
table(day)
sale <- data2$sales
model1 <- lm(sale~day)
data1 <- read.table("HExer.txt", header = TRUE)
data2 <- read.csv("sales.csv", header = TRUE)
day  <- factor(data2$days)
table(day)
sale <- data2$sales
model1 <- lm(sale~day)
anova(model1)
data1 <- read.table("HExer.txt", header = TRUE)
data2 <- read.csv("sales.csv", header = TRUE)
day  <- factor(data2$days)
table(day)
sale <- data2$sales
model1 <- lm(sale~day)
anova(model1)
customer <- data2$customers
model2<-lm(sale ~ day * customer)
anova(model2)
data1 <- read.table("HExer.txt", header = TRUE)
data2 <- read.csv("sales.csv", header = TRUE)
day  <- factor(data2$days)
table(day)
sale <- data2$sales
model1 <- lm(sale~day)
anova(model1)
customer <- factor(data2$customers)
model2<-lm(sale ~ day * customer)
anova(model2)
data1 <- read.table("HExer.txt", header = TRUE)
data2 <- read.csv("sales.csv", header = TRUE)
day  <- factor(data2$days)
table(day)
sale <- data2$sales
model1 <- lm(sale~day)
anova(model1)
customer <- data2$customers
model2<-lm(sale ~ day * customer)
anova(model2)
quantile(data1, type=7)
View(data1)
quantile(data1$HExer, type=7)
hexer <- data1$HExer
t.test(hexer, conf.level = 0.90)
wilcox.test(hexer,mu=10,exact=TRUE)
binom.test(sum(exer), 20, conf.level = 0.95, alternative="less")
binom.test(sum(hexer), 20, conf.level = 0.95, alternative="less")
binom.test(hexer, 20, conf.level = 0.95, alternative="less")
prop.test(hexer, 20, conf.level = 0.95, alternative="less")
binom.test(sum(hexer[hexer>10]), 20, conf.level = 0.95, alternative="less")
binom.test(length(hexer[hexer>10]), 20, conf.level = 0.95, alternative="less")
model3<-lm(sale ~ customer)
anova(modl3)
model3<-lm(sale ~ customer)
anova(model3)
model3<-lm(sale ~ customer)
summary(model3)
confint(model3)
newdata <- data.frame(customer = 200)
predict(model3, newdata, interval = "confidence", level = 0.90)
day  <- factor(data2$days)
table(day)
model1 <- lm(customer~day)
anova(model1)
View(data2)
weekdays = day[day == [Mon, Tue, Wed, Thu, Fri]]
weekdays = day[day == c(Mon, Tue, Wed, Thu, Fri)]
library(EMT)
?multinomial.test
library(EMT)
multinomial.test(c(length(hexer[hexer<7]), length(hexer[hexer>=7 & hexer<=10]), length(hexer[hexer>10])), c(1/2, 1/2, 1/2))
library(EMT)
multinomial.test(c(length(hexer[hexer<7]), length(hexer[hexer>=7 & hexer<=10]), length(hexer[hexer>10])), c(1/3, 1/3, 1/3))
weekdays = day[day in c(Mon, Tue, Wed, Thu, Fri)]
weekdays = day[c(Mon, Tue, Wed, Thu, Fri)]
weekdays = day[c("Mon", "Tue", "Wed", "Thu", "Fri")]
weekdays <- day[c("Mon", "Tue", "Wed", "Thu", "Fri")]
weekdays
weekdays <- customer[day == "Mon" | day == "Tue"| day == "Wed"| day == "Thu"| day == "Fri")]
weekdays <- customer[day == "Mon" | day == "Tue"| day == "Wed"| day == "Thu"| day == "Fri"]
weekdays
weekdays <- customer[day == "Mon" | day == "Tue"| day == "Wed"| day == "Thu"| day == "Fri"]
weekdays
weekends <- customer[day == "Sat" | day == "Sun"]
weekdays <- customer[day == "Mon" | day == "Tue"| day == "Wed"| day == "Thu"| day == "Fri"]
weekdays
weekends <- customer[day == "Sat" | day == "Sun"]
t.test(weekdays, weekends)
binom.test(length(hexer[hexer>10]), 20, conf.level = 0.95, alternative="less")
length(hexer[hexer>10])/20 - qbinom(0.05, 20, 1/2)*sd(hexer)/sqrt(20)
binom.test(length(hexer[hexer>10]), 20, conf.level = 0.95, alternative="less")
length(hexer[hexer>10])/20
binom.test(length(hexer[hexer>10]), 20, conf.level = 0.95, alternative="less")
length(hexer[hexer>10])
binom.test(length(hexer[hexer>10]), 20, conf.level = 0.95, alternative="less")
length(hexer[hexer>10])/20 - qbinom(0.05, 20, 1/2)*sd(hexer)/sqrt(20)
binom.test(length(hexer[hexer>10]), 20, conf.level = 0.95, alternative="less")
length(hexer[hexer>10])/20 - qbinom(0.95, 20, 1/2)*sd(hexer)/sqrt(20)
binom.test(length(hexer[hexer>10]), 20, conf.level = 0.95, alternative="less")
length(hexer[hexer>10])/20 - qbinom(0.05, 20, 1/2)*sd(hexer)/sqrt(20)
binom.test(length(hexer[hexer>10]), 20, conf.level = 0.95, alternative="less")
length(hexer[hexer>10])/20 - qbinom(0.05, 20, 1/2)*sd(hexer)/sqrt(20)
?multinomial.test
library(EMT)
multinomial.test(c(length(hexer[hexer<7]), length(hexer[hexer>=7 & hexer<=10]), length(hexer[hexer>10])), c(1/3, 1/3, 1/3))
plotMultinom(out)
library(EMT)
out <- multinomial.test(c(length(hexer[hexer<7]), length(hexer[hexer>=7 & hexer<=10]), length(hexer[hexer>10])), c(1/3, 1/3, 1/3))
plotMultinom(out)
weekdays <- customer[day == "Mon" | day == "Tue"| day == "Wed"| day == "Thu"| day == "Fri"]
weekends <- customer[day == "Sat" | day == "Sun"]
t.test(weekdays, weekends)
weekday <- factor(days, levels = "Mon", "Tue", "Wed", "Thu","Fri")
weekdays <- customer[day == "Mon" | day == "Tue"| day == "Wed"| day == "Thu"| day == "Fri"]
weekends <- customer[day == "Sat" | day == "Sun"]
t.test(weekdays, weekends)
weekday <- factor(day, levels = "Mon", "Tue", "Wed", "Thu","Fri")
weekdays <- customer[day == "Mon" | day == "Tue"| day == "Wed"| day == "Thu"| day == "Fri"]
weekends <- customer[day == "Sat" | day == "Sun"]
t.test(weekdays, weekends)
weekday <- factor(day, levels = c("Mon", "Tue", "Wed", "Thu","Fri"))
weekday
library(EMT)
#out <- multinomial.test(c(length(hexer[hexer<7]), length(hexer[hexer>=7 & hexer<=10]), length(hexer[hexer>10])), c(1/3, 1/3, 1/3))
#plotMultinom(out)
multinomial.test(c(length(hexer[hexer<7]), length(hexer[hexer>=7 & hexer<=10]), length(hexer[hexer>10])), c(1/3, 1/3, 1/3))
binom.test(length(hexer[hexer>10]), 20, conf.level = 0.05, alternative="less")
length(hexer[hexer>10])/20 - qbinom(0.05, 20, 1/2)*sd(hexer)/sqrt(20)
?multinomial.test
binom.test(length(hexer[hexer>10]), 20, conf.level = 0.95, alternative="greater")
length(hexer[hexer>10])/20 - qbinom(0.05, 20, 1/2)*sd(hexer)/sqrt(20)
?multinomial.test
binom.test(length(hexer[hexer>10]), 20, conf.level = 0.95, alternative="less")
length(hexer[hexer>10])/20 - qbinom(0.05, 20, 1/2)*sd(hexer)/sqrt(20)
?multinomial.test
newdata <- data.frame(customer = 200)
predict(model3, newdata, interval = "confidence", level = 0.90)
predict(model3, newdata, interval = "prediction", level = 0.90)
binom.test(length(hexer[hexer>10]), 20, conf.level = 0.95, alternative="less")
length(hexer[hexer>10])/20 - qbinom(0.05, 20, 1/2)*sd(hexer)/sqrt(20)
?multinomial.test
binom.test(length(hexer[hexer>10]), 20, conf.level = 0.05, alternative="less")
length(hexer[hexer>10])/20 - qbinom(0.05, 20, 1/2)*sd(hexer)/sqrt(20)
?multinomial.test
binom.test(length(hexer[hexer>10]), 20, conf.level = 0.05, alternative="less")
binom.test(length(hexer[hexer>10]), 20, conf.level = 0.95, alternative="greater")
length(hexer[hexer>10])/20 - qbinom(0.05, 20, 1/2)*sd(hexer)/sqrt(20)
?multinomial.test
?qchisq
?dpois
demo()
glm.vr
demo(glm.vr)
demo(lm.glm)
# install.packages("mgcv") # package to fit GAM
# install.packages("tidyverse") # for data transformation and plotting
library(mgcv)
library(tidyverse)
# default gam example
set.seed(2) ## simulate some data...
dat <- gamSim(1,n=400,dist="normal",scale=2)
b <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),data=dat)
summary(b)
plot(b,pages=1,residuals=TRUE)  ## show partial residuals
## run some basic model checks, including checking
## smoothing basis dimensions...
gam.check(b)
# time index
times <- seq(1,180)
# lambda for Poisson distributed count through time
true_lambda <- round((2 + sin(times/30)) * 5, digits = 1)
# generate draws
set.seed(42)
obs <- sapply(true_lambda,rpois, n = 10)
# put together data
dat <- data.frame(times, t(obs)) %>% pivot_longer(cols = 2:11, names_to = NULL)
# check
plot(dat$times,dat$value)
# fit model
m <- gam(value~s(times),data=dat)
summary(m)
plot(m)
m.pred <- predict.gam(m, newdata = data.frame(times))
plot(dat$times,dat$value)
plot(b,pages=1,residuals=TRUE)  ## show partial residuals
plot(b,pages=1,seWithMean=TRUE) ## `with intercept' CIs
?seWithMean
??seWithMean
?plot
## run some basic model checks, including checking
## smoothing basis dimensions...
gam.check(b)
?sapply
# check
plot(dat$times,dat$value)
?pivot_longer
# put together data
dat <- data.frame(times, t(obs)) %>% pivot_longer(cols = 2:11, names_to = NULL)
dat
print(n=21)
print(dat, n=21)
# check
plot(dat$times,dat$value)
# fit model
m <- gam(value~s(times),data=dat)
summary(m)
plot(m)
# check
plot(dat$times,dat$value)
plot(m)
# plot against data
m.pred <- predict.gam(m, newdata = data.frame(times))
plot(dat$times,dat$value)
points(times,m.pred, col = "red")
library(tidyverse)
library(dplyr)
source("R/seasonalities2.R")
# Smooth of day only
mDay <- gam(contacts~s(days, k=100),
data,
family = poisson(link = "log"),
method = 'REML')
library(mgcv)
library(tidyverse)
source("simulator2.R")
source("simulator2.R")
source("simulator2.R")
source("simulator2.R")
singlePredModels <- list(mDay, mLockdown, mWeekdate, mSchoolHoliday, mPublicHoliday, mMonth, mYear, mTemperature)
mDays <- gam(contacts ~ days,
data,
family = poisson(link="log"),
method = 'REML');
library(mgcv)
library(tidyverse)
source("simulator2.R")
library(mgcv)
library(tidyverse)
library(expss)
library(gridExtra) # coplot
source("simulator2.R")
getwd()
setwd("~/Desktop/University/Year_2/Vacation Scholarship Program/VS_student_project/R")
source("simulator2.R")
source("crossValidationFunctions.R");
source("plotModel.R")
data <- getObservedData()
seasonalitiesData <- getSeasonalities()
#````````````````````````````````````````````````````````````
# Initial data manipulation
#````````````````````````````````````````````````````````````
# Convert weekdate to weekends to simplify parameters````````
weekdateToWeekend <- function(weekdate) {
weekdate[weekdate == "Monday" | weekdate == "Tuesday" | weekdate == "Wednesday"
| weekdate == "Thursday" | weekdate == "Friday"] <- FALSE
weekdate[weekdate == "Saturday" | weekdate == "Sunday"] <- TRUE
return (as.logical(weekdate))
}
data$weekdate <- weekdateToWeekend(data$weekdate)
seasonalitiesData$weekdate <- weekdateToWeekend(seasonalitiesData$weekdate)
# Convert categorical variables to factors to use as potential by variable for smoothing term
#data$weekdate <- factor(data$weekdate, levels = c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'), ordered = TRUE)
data$weekdate <- as.factor(data$weekdate)
data$lockdown <- as.factor(data$lockdown)
data$schoolHoliday <- as.factor(data$schoolHoliday)
data$publicHoliday <- as.factor(data$publicHoliday)
crossValidateGam(data = data,
partition,
train,
test,
evaluate
)
changeSmoothDayOnlyModelKnots <- function(data, nKnots) {
return(gam(contacts ~ s(days, k = nKnots),
data = data,
family = poisson(link = "log"),
method="REML"))
}
changeFinalModelKnots <- function(data, nKnots) {
return(gam(contacts ~ s(days, by = lockdown, k = nKnots) +
s(temperature, k = 10) + weekdate + schoolHoliday + publicHoliday,
data = data,
family = poisson(link = "log")))
}
knotsTuningPlot(data, partition, changeSmoothDayOnlyModelKnots, test, evaluate,
2, 50);
# plot number of knots VS RMSE graph for smoothing term knots tuning
knotsTuningPlot <- function(data, partition, changeKnotsTrain, test, evaluate,
nKnotsLowerBound, nKnotsUpperBound) {
knots_tune_RMSE_list <- list(NULL)
for (knot in nKnotsLowerBound:nKnotsUpperBound) {
train <- function(data) {
return (changeKnotsTrain(data, knot))
}
knots_tune_RMSE_list[[knot]] <- crossValidateGam(data, partition, train, test, evaluate)
print(paste(knot, knots_tune_RMSE_list[[knot]]))
}
nKnots <- nKnotsLowerBound:nKnotsUpperBound
knots_RMSE_df <- data.frame(unlist(nKnots), unlist(knots_tune_RMSE_list))
colnames(knots_RMSE_df)[1] <- "nKnots"
colnames(knots_RMSE_df)[2] <-  "RMSE"
knots_RMSE_df$lab <- paste("k =", knots_RMSE_df$nKnots, ", \nRMSE:", format(round(knots_RMSE_df$RMSE, 2), digits = 3, format = "f"))
model_knots_tune_plot <- ggplot(data = knots_RMSE_df, aes(x = nKnots, y = log(RMSE))) +
geom_smooth(se = FALSE, method = "gam", formula = y ~ s(x, k=30), color="darkgrey") +
geom_line(color="grey") +
geom_point(color="black", size=2) +
geom_point(data = knots_RMSE_df[which.min(knots_RMSE_df$RMSE), ], color="blue", size=4) +
geom_text(data = knots_RMSE_df[which.min(knots_RMSE_df$RMSE), ], aes(nKnots, log(RMSE)+1, label=lab),color="blue") +
labs(title="Smoothing Term Tuning Without Mechanistic Predictors: Knots VS Cross Validated RMSE",
x="Number of Knots",
y="ln(RMSE)")
return(model_knots_tune_plot)
}
knotsTuningPlot(data, partition, changeSmoothDayOnlyModelKnots, test, evaluate,
2, 50);
